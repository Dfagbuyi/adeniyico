{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project 355",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dfagbuyi/adeniyico/blob/master/Final_Project_355.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDwYNg-FpSBf",
        "colab_type": "text"
      },
      "source": [
        "# PIP Installs \n",
        "  Tensor Flow, NLTK, SEABORN\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtzJ5xpAkBX1",
        "colab_type": "code",
        "outputId": "4cf47f39-c15b-40b9-8b58-f40dcab8ca1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install seaborn\n",
        "!pip3 install nltk\n",
        "!pip3 install requests\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.2.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.16.3)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA_4vKq_hcH_",
        "colab_type": "code",
        "outputId": "b7ff8237-1aa0-4207-fa10-64400a8f27f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import bs4\n",
        "import nltk\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import requests\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0502 17:25:50.263520 140096838756224 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWrS800ihw2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmE9SiqJjvXJ",
        "colab_type": "code",
        "outputId": "11d03d37-8693-4754-eb44-6b2224aa3532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "embed = hub.Module(module_url)\n",
        "\n",
        "board = []\n",
        "rankings = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def cosine_similarity():\n",
        "   for sent in board:\n",
        "      sent[1] = dot(topic_embedding, sent[1])/(norm(topic_embedding)*norm(sent[1]))\n",
        "      rankings.append(sent)\n",
        "\n",
        "\n",
        "def takeSecond(elem):\n",
        "    return elem[1]\n",
        "  \n",
        "def add_page(wikipage):\n",
        "  response = requests.get(\"https://en.wikipedia.org/wiki/\"+str(wikipage))\n",
        "  if response is not None:\n",
        "    html = bs4.BeautifulSoup(response.text, 'html.parser')\n",
        "    title = html.select(\"#firstHeading\")[0].text\n",
        "    paragraphs = html.select(\"p\")\n",
        "    for para in paragraphs:\n",
        "      source = ' '.join([ para.text for para in paragraphs])\n",
        "      return nltk.sent_tokenize(source)\n",
        "  \n",
        "def print_summary(ranking10):\n",
        "  paragraph = ' '.join([ para[0] for para in ranking10])\n",
        "  word_box = paragraph.split()\n",
        "  count = 0\n",
        "  for word in word_box:\n",
        "    count = count + 1\n",
        "    if(check_annotation(word)):\n",
        "      if( count >= 30):\n",
        "        print(word, end='\\n')\n",
        "        count = 0\n",
        "      else:\n",
        "        print(word, end=' ')\n",
        "        \n",
        "def check_annotation(word):\n",
        "  if(word[-1] == \"]\" and word[0]== \"[\"):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "      \n",
        "\n",
        "\n",
        "method = int(input('Input a method of calculating similarity , 1: Direct Input , 2: Wikipage Search '))\n",
        "if(method == 1):\n",
        "    topic = input('Input a topic sentence: ')\n",
        "    source = input('Input at least 5 sentences.: ')\n",
        "    sent_text = nltk.sent_tokenize(source) \n",
        "\n",
        "elif(method == 2):\n",
        "    wikipage = input('Input a wikipage title: ')\n",
        "    topic = input('Input a topic sentence: ')\n",
        "    sent_text = add_page(wikipage)\n",
        "else:\n",
        "   raise ValueError('Input Method has to be either 1 or 2.')\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "    # Stops the over loggings\n",
        "sent_num = 0\n",
        "while(True):\n",
        "  with tf.Session() as session:\n",
        "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "    message_embeddings = session.run(embed(sent_text))\n",
        "    topic_embedding = session.run(embed([topic]))\n",
        "    for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "      message_embedding_snippet = \", \".join(\n",
        "          (str(x) for x in message_embedding[:3]))\n",
        "      message_and_score = list((sent_text[i],message_embedding,i))\n",
        "      board.append(message_and_score)\n",
        "  cosine_similarity()\n",
        "  rankings.sort(key=takeSecond, reverse = True )\n",
        "  num_of_sents = len(board)\n",
        "  print_summary(rankings[:10])\n",
        "  if(method == 2):\n",
        "    wikipage = input(\"Extend the search with additional wikipages or enter 'END' : \")\n",
        "    if(wikipage != \"END\"):\n",
        "      board = []\n",
        "      sent_text = add_page(wikipage)\n",
        "    else:\n",
        "      break;\n",
        "               \n",
        "\n",
        "          \n",
        "    \n",
        "\n",
        "          \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input a method of calculating similarity , 1: Direct Input , 2: Wikipage Search 2\n",
            "Input a wikipage title: World War II\n",
            "Input a topic sentence: Nazi activity in the war\n",
            "The blitzkrieg phase of the war in Europe had ended. This Eastern Front trapped the Axis, most crucially the German Wehrmacht, into a war of attrition. The Polish counter offensive\n",
            "to the west halted the German advance for several days, but it was outflanked and encircled by the Wehrmacht. Soviet and Polish forces stormed and captured Berlin in late April.\n",
            "By mid-November, the Germans had nearly taken Stalingrad in bitter street fighting. The Allies established occupation administrations in Austria and Germany. On 11 July, Allied leaders met\n",
            "in Potsdam, Germany. In Italy, the Western Allies remained stalemated at the German defensive line. The Battle of Britain[102] began in early July with Luftwaffe attacks on shipping\n",
            "and harbours. In early April, Soviet troops captured KÃ¶nigsberg, while the Western Allies finally pushed forward in Italy and swept across western Germany capturing Hamburg and Nuremberg. "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgcfBu4snW8t",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twCX_G8pucOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk_LOqKurskK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etCPj0bnBkbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYZWi2PcgL3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}